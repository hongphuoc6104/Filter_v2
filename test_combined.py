"""
Filter v2: B·ªô L·ªçc Ch·∫•t L∆∞·ª£ng ·∫¢nh Label
======================================

Ch·ª©c nƒÉng:
  - L·ªçc ·∫£nh theo 4 ti√™u ch√≠: size, contrast, sharpness, brightness
  - [Option] Chu·∫©n h√≥a ·∫£nh FIXABLE v·ªÅ m·ª©c target
  - [Option] Ph√°t hi·ªán QR Code
  - [Option] Nh·∫≠n d·∫°ng ch·ªØ (OCR)

Usage:
  # Ch·ªâ l·ªçc (m·∫∑c ƒë·ªãnh)
  python test_combined.py
  
  # L·ªçc + Chu·∫©n h√≥a ·∫£nh FIXABLE
  python test_combined.py --normalize
  
  # L·ªçc + QR Detection
  python test_combined.py --qr
  
  # L·ªçc + Chu·∫©n h√≥a + QR + OCR (ƒë·∫ßy ƒë·ªß)
  python test_combined.py --normalize --qr --ocr

Output:
  Output/
  ‚îú‚îÄ‚îÄ 1_discard/     - ·∫¢nh b·ªã lo·∫°i
  ‚îú‚îÄ‚îÄ 2_fixable/     - ·∫¢nh c·∫ßn x·ª≠ l√Ω (ho·∫∑c ƒë√£ x·ª≠ l√Ω n·∫øu --normalize)
  ‚îî‚îÄ‚îÄ 3_good/        - ·∫¢nh t·ªët
"""

import os
import sys
import shutil
import json
import argparse
from dataclasses import dataclass, asdict
from enum import Enum
from typing import Tuple, Optional
from datetime import datetime

import cv2
import numpy as np

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))


# ==============================================================================
# ENUM & DATACLASS
# ==============================================================================
class QualityOutcome(Enum):
    GOOD = "good"
    FIXABLE = "fixable"
    DISCARD = "discard"


@dataclass
class Metrics:
    width: int
    height: int
    brightness: float
    contrast: float
    sharpness: float


# ==============================================================================
# NG∆Ø·ª†NG L·ªåC (S3b)
# ==============================================================================
FILTER_THRESHOLDS = {
    "size": {
        "good": {"minWidth": 300, "minHeight": 200},
        "fixable": {"minWidth": 200, "minHeight": 150}
    },
    "contrast": {
        "good": 55,       # >= 55 l√† t·ªët, kh√¥ng c·∫ßn x·ª≠ l√Ω
        "fixable": 50     # >= 50 m·ªõi l·∫•y, < 50 b·ªã lo·∫°i
    },
    "sharpness": {
        "good": 500,      # >= 500 l√† s·∫Øc n√©t
        "fixable": 200    # 200-499 c·∫ßn normalize
    },
    "brightness": {
        "good": {"min": 80, "max": 220},
        "fixable": {"min": 60, "max": 240}  # Gi·ªØ nguy√™n nh∆∞ ban ƒë·∫ßu
    }
}

# ==============================================================================
# M·ª®C CHU·∫®N TARGET (S4)
# ==============================================================================
NORMALIZE_TARGET = {
    "size": (300, 200),           # width, height
    "brightness": 150,            # mean pixel value
    "contrast": 60,               # std deviation
    "sharpness": 600,             # Laplacian variance
}


# ==============================================================================
# H√ÄM T√çNH METRICS
# ==============================================================================
def calculate_metrics(image: np.ndarray) -> Metrics:
    height, width = image.shape[:2]
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    
    brightness = float(np.mean(gray))
    contrast = float(np.std(gray))
    laplacian = cv2.Laplacian(gray, cv2.CV_64F)
    sharpness = float(laplacian.var())
    
    return Metrics(
        width=width,
        height=height,
        brightness=round(brightness, 2),
        contrast=round(contrast, 2),
        sharpness=round(sharpness, 2)
    )


# ==============================================================================
# B·ªò L·ªåC (S3b): Ph√¢n lo·∫°i GOOD / FIXABLE / DISCARD
# ==============================================================================
def filter_image(metrics: Metrics) -> Tuple[QualityOutcome, Optional[str], dict]:
    """
    Ph√¢n lo·∫°i ·∫£nh th√†nh 3 m·ª©c.
    
    Returns:
        (outcome, discard_reason, needs_fix)
        needs_fix = {"size": bool, "brightness": bool, "contrast": bool, "sharpness": bool}
    """
    t = FILTER_THRESHOLDS
    needs_fix = {"size": False, "brightness": False, "contrast": False, "sharpness": False}
    
    # Check SIZE
    if metrics.width < t["size"]["fixable"]["minWidth"] or \
       metrics.height < t["size"]["fixable"]["minHeight"]:
        return QualityOutcome.DISCARD, f"Size qu√° nh·ªè ({metrics.width}x{metrics.height})", needs_fix
    elif metrics.width < t["size"]["good"]["minWidth"] or \
         metrics.height < t["size"]["good"]["minHeight"]:
        needs_fix["size"] = True
    
    # Check CONTRAST
    if metrics.contrast < t["contrast"]["fixable"]:
        return QualityOutcome.DISCARD, f"Contrast qu√° th·∫•p ({metrics.contrast})", needs_fix
    elif metrics.contrast < t["contrast"]["good"]:
        needs_fix["contrast"] = True
    
    # Check SHARPNESS
    if metrics.sharpness < t["sharpness"]["fixable"]:
        return QualityOutcome.DISCARD, f"·∫¢nh qu√° m·ªù ({metrics.sharpness})", needs_fix
    elif metrics.sharpness < t["sharpness"]["good"]:
        needs_fix["sharpness"] = True
    
    # Check BRIGHTNESS
    if metrics.brightness < t["brightness"]["fixable"]["min"]:
        return QualityOutcome.DISCARD, f"·∫¢nh qu√° t·ªëi ({metrics.brightness})", needs_fix
    elif metrics.brightness > t["brightness"]["fixable"]["max"]:
        return QualityOutcome.DISCARD, f"·∫¢nh qu√° s√°ng ({metrics.brightness})", needs_fix
    elif metrics.brightness < t["brightness"]["good"]["min"] or \
         metrics.brightness > t["brightness"]["good"]["max"]:
        needs_fix["brightness"] = True
    
    # Quy·∫øt ƒë·ªãnh
    if any(needs_fix.values()):
        return QualityOutcome.FIXABLE, None, needs_fix
    else:
        return QualityOutcome.GOOD, None, needs_fix


# ==============================================================================
# B·ªò CHU·∫®N H√ìA (S4): Normalize v·ªÅ target - CH·ªà X·ª¨ L√ù NH·ªÆNG G√å C·∫¶N FIX
# ==============================================================================
def normalize_size(image: np.ndarray, target: Tuple[int, int]) -> np.ndarray:
    h, w = image.shape[:2]
    target_w, target_h = target
    
    if w == target_w and h == target_h:
        return image.copy()
    
    if w < target_w or h < target_h:
        interpolation = cv2.INTER_CUBIC
    else:
        interpolation = cv2.INTER_AREA
    
    return cv2.resize(image, target, interpolation=interpolation)


def normalize_brightness(image: np.ndarray, target: float) -> np.ndarray:
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    current = float(np.mean(gray))
    
    if abs(current - target) < 5:
        return image.copy()
    
    adjustment = target - current
    
    if abs(adjustment) > 30:
        lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
        l, a, b = cv2.split(lab)
        clip_limit = min(abs(adjustment) / 10, 4.0)
        clip_limit = max(clip_limit, 2.0)
        clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=(8, 8))
        l = clahe.apply(l)
        
        after_mean = float(np.mean(l))
        remaining = target - after_mean
        if abs(remaining) > 10:
            l = cv2.add(l, int(remaining * 0.5))
        
        lab = cv2.merge([l, a, b])
        return cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)
    else:
        return cv2.convertScaleAbs(image, alpha=1.0, beta=adjustment)


def normalize_contrast(image: np.ndarray, target: float) -> np.ndarray:
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    current = float(np.std(gray))
    
    if abs(current - target) < 5 or current < 1:
        return image.copy()
    
    scale = np.clip(target / current, 0.5, 2.5)
    
    result = image.astype(np.float32)
    for c in range(3):
        mean = np.mean(result[:, :, c])
        result[:, :, c] = (result[:, :, c] - mean) * scale + mean
    
    return np.clip(result, 0, 255).astype(np.uint8)


def normalize_sharpness(image: np.ndarray, target: float) -> np.ndarray:
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    laplacian = cv2.Laplacian(gray, cv2.CV_64F)
    current = float(laplacian.var())
    
    if current >= target or current < 10:
        return image.copy()
    
    ratio = target / current
    amount = np.clip((ratio - 1) * 0.8, 0.5, 3.0)
    
    blurred = cv2.GaussianBlur(image, (0, 0), 1.0)
    return cv2.addWeighted(image, 1 + amount, blurred, -amount, 0)


def normalize_image(image: np.ndarray, needs_fix: dict) -> np.ndarray:
    """
    Ch·ªâ normalize nh·ªØng g√¨ c·∫ßn fix.
    """
    result = image.copy()
    
    if needs_fix["size"]:
        result = normalize_size(result, NORMALIZE_TARGET["size"])
    
    if needs_fix["brightness"]:
        result = normalize_brightness(result, NORMALIZE_TARGET["brightness"])
    
    if needs_fix["contrast"]:
        result = normalize_contrast(result, NORMALIZE_TARGET["contrast"])
    
    if needs_fix["sharpness"]:
        result = normalize_sharpness(result, NORMALIZE_TARGET["sharpness"])
    
    return result


# ==============================================================================
# QR DETECTION (S5)
# ==============================================================================
def detect_qr(image: np.ndarray) -> Tuple[bool, Optional[str]]:
    try:
        import zxingcpp
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        barcodes = zxingcpp.read_barcodes(gray)
        
        if barcodes:
            for bc in barcodes:
                if bc.valid:
                    return True, bc.text
        return False, None
    except Exception as e:
        return False, str(e)


# ==============================================================================
# OCR DETECTION (S7) - Singleton ƒë·ªÉ tr√°nh load model nhi·ªÅu l·∫ßn
# ==============================================================================
_ocr_engine = None

def get_ocr_engine():
    """Lazy load PaddleOCR engine."""
    global _ocr_engine
    if _ocr_engine is None:
        from paddleocr import PaddleOCR
        import logging
        # Suppress PaddleOCR logs
        logging.getLogger("ppocr").setLevel(logging.ERROR)
        _ocr_engine = PaddleOCR(
            lang='en',
            use_doc_orientation_classify=False,
            use_doc_unwarping=False,
            use_textline_orientation=False,
        )
        print("   PaddleOCR engine loaded.")
    return _ocr_engine


def detect_ocr(image: np.ndarray) -> Tuple[bool, list]:
    """
    Detect text using PaddleOCR.
    
    Returns:
        (success, texts): (bool, list of detected texts)
    """
    try:
        ocr = get_ocr_engine()
        result = ocr.predict(image)
        
        texts = []
        if result:
            for res in result:
                rec_texts = res.get('rec_texts', [])
                rec_scores = res.get('rec_scores', [])
                for i, text in enumerate(rec_texts):
                    score = rec_scores[i] if i < len(rec_scores) else 0
                    if score > 0.5:  # Ch·ªâ l·∫•y text confidence > 0.5
                        texts.append({"text": text, "confidence": round(score, 3)})
        
        return len(texts) > 0, texts
    except Exception as e:
        return False, [{"error": str(e)}]


def save_image_info(folder: str, filename: str, info: dict):
    """Save JSON info file alongside image."""
    json_filename = os.path.splitext(filename)[0] + "_info.json"
    json_path = os.path.join(folder, json_filename)
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(info, f, indent=2, ensure_ascii=False)


# ==============================================================================
# MAIN PROCESSING
# ==============================================================================
def process_images(input_dir: str, output_dir: str, 
                   enable_normalize: bool = False,
                   enable_qr: bool = False,
                   enable_ocr: bool = False,
                   max_images: int = None):
    """
    X·ª≠ l√Ω ·∫£nh v·ªõi c√°c option.
    
    Args:
        input_dir: Th∆∞ m·ª•c ch·ª©a ·∫£nh ƒë·∫ßu v√†o
        output_dir: Th∆∞ m·ª•c l∆∞u k·∫øt qu·∫£
        enable_normalize: B·∫≠t chu·∫©n h√≥a ·∫£nh FIXABLE
        enable_qr: B·∫≠t ph√°t hi·ªán QR Code
        enable_ocr: B·∫≠t nh·∫≠n d·∫°ng ch·ªØ (OCR)
        max_images: Gi·ªõi h·∫°n s·ªë ·∫£nh x·ª≠ l√Ω (None = t·∫•t c·∫£)
    """
    # T·∫°o th∆∞ m·ª•c output
    if enable_qr:
        # N·∫øu b·∫≠t QR, chia th√†nh detected/not_detected
        dirs = {
            "discard": os.path.join(output_dir, "1_discard"),
            "fixable_detected": os.path.join(output_dir, "2_fixable", "detected"),
            "fixable_not_detected": os.path.join(output_dir, "2_fixable", "not_detected"),
            "good_detected": os.path.join(output_dir, "3_good", "detected"),
            "good_not_detected": os.path.join(output_dir, "3_good", "not_detected"),
        }
    else:
        # Ch·ªâ l·ªçc, kh√¥ng c·∫ßn chia detected/not_detected
        dirs = {
            "discard": os.path.join(output_dir, "1_discard"),
            "fixable": os.path.join(output_dir, "2_fixable"),
            "good": os.path.join(output_dir, "3_good"),
        }
    
    for d in dirs.values():
        os.makedirs(d, exist_ok=True)
    
    image_files = [f for f in os.listdir(input_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
    if max_images:
        image_files = image_files[:max_images]
    
    # Header
    print("=" * 70)
    print("üîç FILTER v2: B·ªò L·ªåC CH·∫§T L∆Ø·ª¢NG ·∫¢NH")
    print("=" * 70)
    print(f"üìÇ Input:  {input_dir}")
    print(f"üìÇ Output: {output_dir}")
    print(f"üì∑ Images: {len(image_files)}")
    print(f"")
    print(f"‚öôÔ∏è  Options:")
    print(f"   Normalize: {'‚úÖ ON' if enable_normalize else '‚ùå OFF'}")
    print(f"   QR Detect: {'‚úÖ ON' if enable_qr else '‚ùå OFF'}")
    print(f"   OCR:       {'‚úÖ ON' if enable_ocr else '‚ùå OFF'}")
    print("=" * 70)
    
    stats = {
        "discard": 0,
        "good": 0,
        "fixable": 0,
        # Chi ti·∫øt khi b·∫≠t QR
        "good_detected": 0,
        "good_not_detected": 0,
        "fixable_detected": 0,
        "fixable_not_detected": 0,
        # OCR stats
        "ocr_success": 0,
        "ocr_fail": 0,
    }
    
    results = []
    
    for i, filename in enumerate(image_files, 1):
        filepath = os.path.join(input_dir, filename)
        image = cv2.imread(filepath)
        
        if image is None:
            continue
        
        metrics = calculate_metrics(image)
        outcome, discard_reason, needs_fix = filter_image(metrics)
        
        # Kh·ªüi t·∫°o bi·∫øn
        qr_ok = None
        qr_text = None
        ocr_ok = None
        ocr_texts = []
        final_image = image
        fixes = [k for k, v in needs_fix.items() if v]
        
        if outcome == QualityOutcome.DISCARD:
            # B·ªè ·∫£nh
            dest_folder = dirs["discard"]
            shutil.copy(filepath, os.path.join(dest_folder, filename))
            stats["discard"] += 1
            status = f"‚ùå DISCARD: {discard_reason}"
            
            # L∆∞u info
            save_image_info(dest_folder, filename, {
                "filename": filename,
                "outcome": "discard",
                "reason": discard_reason,
                "metrics": asdict(metrics),
                "thresholds": FILTER_THRESHOLDS
            })
            
        elif outcome == QualityOutcome.GOOD:
            stats["good"] += 1
            
            # QR Detection (n·∫øu b·∫≠t)
            if enable_qr:
                qr_ok, qr_text = detect_qr(image)
            
            # OCR (n·∫øu b·∫≠t)
            if enable_ocr:
                ocr_ok, ocr_texts = detect_ocr(image)
                if ocr_ok:
                    stats["ocr_success"] += 1
                else:
                    stats["ocr_fail"] += 1
            
            # L∆∞u ·∫£nh
            if enable_qr:
                if qr_ok:
                    dest_folder = dirs["good_detected"]
                    stats["good_detected"] += 1
                    status = f"‚úÖ GOOD ‚Üí QR ‚úì"
                else:
                    dest_folder = dirs["good_not_detected"]
                    stats["good_not_detected"] += 1
                    status = f"‚úÖ GOOD ‚Üí QR ‚úó"
                if enable_ocr:
                    status += f" | OCR {'‚úì' if ocr_ok else '‚úó'}"
            else:
                dest_folder = dirs["good"]
                status = f"‚úÖ GOOD"
                if enable_ocr:
                    status += f" | OCR {'‚úì' if ocr_ok else '‚úó'}"
            
            shutil.copy(filepath, os.path.join(dest_folder, filename))
            
            # L∆∞u info
            info = {
                "filename": filename,
                "outcome": "good",
                "metrics": asdict(metrics),
                "processing": "none"
            }
            if enable_qr:
                info["qr_detected"] = qr_ok
                info["qr_text"] = qr_text
            if enable_ocr:
                info["ocr_detected"] = ocr_ok
                info["ocr_texts"] = ocr_texts
            save_image_info(dest_folder, filename, info)
                
        else:  # FIXABLE
            stats["fixable"] += 1
            before_metrics = metrics
            
            # Normalize (n·∫øu b·∫≠t)
            if enable_normalize:
                final_image = normalize_image(image, needs_fix)
                after_metrics = calculate_metrics(final_image)
            else:
                final_image = image
                after_metrics = metrics
            
            # QR Detection (n·∫øu b·∫≠t)
            if enable_qr:
                qr_ok, qr_text = detect_qr(final_image)
            
            # OCR (n·∫øu b·∫≠t)
            if enable_ocr:
                ocr_ok, ocr_texts = detect_ocr(final_image)
                if ocr_ok:
                    stats["ocr_success"] += 1
                else:
                    stats["ocr_fail"] += 1
            
            # L∆∞u ·∫£nh
            if enable_qr:
                if qr_ok:
                    dest_folder = dirs["fixable_detected"]
                    stats["fixable_detected"] += 1
                    status = f"üîß FIXABLE ({', '.join(fixes)}) ‚Üí QR ‚úì"
                else:
                    dest_folder = dirs["fixable_not_detected"]
                    stats["fixable_not_detected"] += 1
                    status = f"üîß FIXABLE ({', '.join(fixes)}) ‚Üí QR ‚úó"
                if enable_ocr:
                    status += f" | OCR {'‚úì' if ocr_ok else '‚úó'}"
            else:
                dest_folder = dirs["fixable"]
                status = f"üîß FIXABLE ({', '.join(fixes)})"
                if enable_normalize:
                    status += " ‚Üí Normalized"
                if enable_ocr:
                    status += f" | OCR {'‚úì' if ocr_ok else '‚úó'}"
            
            if enable_normalize:
                cv2.imwrite(os.path.join(dest_folder, filename), final_image)
            else:
                shutil.copy(filepath, os.path.join(dest_folder, filename))
            
            # L∆∞u info
            info = {
                "filename": filename,
                "outcome": "fixable",
                "needs_fix": fixes,
                "before_metrics": asdict(before_metrics),
                "processing": "normalized" if enable_normalize else "none"
            }
            if enable_normalize:
                info["after_metrics"] = asdict(after_metrics)
            if enable_qr:
                info["qr_detected"] = qr_ok
                info["qr_text"] = qr_text
            if enable_ocr:
                info["ocr_detected"] = ocr_ok
                info["ocr_texts"] = ocr_texts
            save_image_info(dest_folder, filename, info)
        
        # Log
        if i <= 15 or i % 10 == 0:
            print(f"[{i:3d}] {status}")
        
        results.append({
            "filename": filename,
            "outcome": outcome.value,
            "metrics": asdict(metrics),
            "needs_fix": needs_fix,
            "discard_reason": discard_reason,
            "qr_detected": qr_ok
        })
    
    # Summary
    print("\n" + "=" * 70)
    print("üìä K·∫æT QU·∫¢")
    print("=" * 70)
    print(f"\nüìã Ph√¢n lo·∫°i:")
    print(f"  ‚ùå DISCARD:  {stats['discard']:3d} ·∫£nh (b·ªè)")
    print(f"  ‚úÖ GOOD:     {stats['good']:3d} ·∫£nh (kh√¥ng c·∫ßn x·ª≠ l√Ω)")
    print(f"  üîß FIXABLE:  {stats['fixable']:3d} ·∫£nh", end="")
    if enable_normalize:
        print(" (ƒë√£ normalize)")
    else:
        print(" (c·∫ßn x·ª≠ l√Ω)")
    
    if enable_qr:
        print(f"\nüìç QR Detection:")
        print(f"  GOOD ‚Üí Detected:         {stats['good_detected']:3d}")
        print(f"  GOOD ‚Üí Not detected:     {stats['good_not_detected']:3d}")
        print(f"  FIXABLE ‚Üí Detected:      {stats['fixable_detected']:3d}")
        print(f"  FIXABLE ‚Üí Not detected:  {stats['fixable_not_detected']:3d}")
        
        total_processed = stats['good'] + stats['fixable']
        total_detected = stats["good_detected"] + stats["fixable_detected"]
        if total_processed > 0:
            print(f"\nüìà T·ªâ l·ªá QR Detected: {total_detected}/{total_processed} ({total_detected/total_processed*100:.1f}%)")
    
    if enable_ocr:
        total_ocr = stats['ocr_success'] + stats['ocr_fail']
        if total_ocr > 0:
            print(f"üìà T·ªâ l·ªá OCR Success: {stats['ocr_success']}/{total_ocr} ({stats['ocr_success']/total_ocr*100:.1f}%)")
    
    print("=" * 70)
    
    # Save
    summary = {
        "timestamp": datetime.now().isoformat(),
        "options": {
            "normalize": enable_normalize,
            "qr": enable_qr,
            "ocr": enable_ocr
        },
        "filter_thresholds": FILTER_THRESHOLDS,
        "normalize_target": NORMALIZE_TARGET if enable_normalize else None,
        "stats": stats,
        "results": results
    }
    
    with open(os.path.join(output_dir, "summary.json"), "w", encoding="utf-8") as f:
        json.dump(summary, f, indent=2, ensure_ascii=False)
    
    print(f"\nüìÅ Results saved to: {output_dir}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Filter v2: B·ªô l·ªçc ch·∫•t l∆∞·ª£ng ·∫£nh label",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
V√≠ d·ª•:
  python test_combined.py                      # Ch·ªâ l·ªçc
  python test_combined.py --normalize          # L·ªçc + Chu·∫©n h√≥a
  python test_combined.py --qr                 # L·ªçc + QR Detection
  python test_combined.py --normalize --qr --ocr  # ƒê·∫ßy ƒë·ªß
        """
    )
    
    parser.add_argument("-i", "--input", default="Input",
                        help="Th∆∞ m·ª•c ch·ª©a ·∫£nh ƒë·∫ßu v√†o (m·∫∑c ƒë·ªãnh: Input)")
    parser.add_argument("-o", "--output", default="Output",
                        help="Th∆∞ m·ª•c l∆∞u k·∫øt qu·∫£ (m·∫∑c ƒë·ªãnh: Output)")
    parser.add_argument("--normalize", action="store_true",
                        help="B·∫≠t chu·∫©n h√≥a ·∫£nh FIXABLE")
    parser.add_argument("--qr", action="store_true",
                        help="B·∫≠t ph√°t hi·ªán QR Code")
    parser.add_argument("--ocr", action="store_true",
                        help="B·∫≠t nh·∫≠n d·∫°ng ch·ªØ (OCR)")
    parser.add_argument("-n", "--max-images", type=int, default=None,
                        help="Gi·ªõi h·∫°n s·ªë ·∫£nh x·ª≠ l√Ω")
    
    args = parser.parse_args()
    
    if not os.path.exists(args.input):
        print(f"‚ùå Input directory not found: {args.input}")
        sys.exit(1)
    
    process_images(
        input_dir=args.input,
        output_dir=args.output,
        enable_normalize=args.normalize,
        enable_qr=args.qr,
        enable_ocr=args.ocr,
        max_images=args.max_images
    )
